{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-58cc9e064ab4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import data\n",
    "data = pd.read_csv('data_stocks.csv')\n",
    "\n",
    "# Drop date variable\n",
    "data = data.drop(['DATE'], 1)\n",
    "\n",
    "# Dimensions of dataset\n",
    "n = data.shape[0]\n",
    "p = data.shape[1]\n",
    "\n",
    "# Make data a np.array\n",
    "data = data.values\n",
    "\n",
    "# Training and test data\n",
    "train_start = 0\n",
    "train_end = int(np.floor(0.8*n))\n",
    "test_start = train_end + 1\n",
    "test_end = n\n",
    "data_train = data[np.arange(train_start, train_end), :]\n",
    "data_test = data[np.arange(test_start, test_end), :]\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(data_train)\n",
    "data_train = scaler.transform(data_train)\n",
    "data_test = scaler.transform(data_test)\n",
    "\n",
    "# Build X and y\n",
    "X_train = data_train[:, 1:]\n",
    "y_train = data_train[:, 0]\n",
    "X_test = data_test[:, 1:]\n",
    "y_test = data_test[:, 0]\n",
    "\n",
    "# Number of stocks in training data\n",
    "n_stocks = X_train.shape[1]\n",
    "\n",
    "# Neurons\n",
    "n_neurons_1 = 1024\n",
    "n_neurons_2 = 512\n",
    "n_neurons_3 = 256\n",
    "n_neurons_4 = 128\n",
    "\n",
    "# Session\n",
    "net = tf.InteractiveSession()\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_stocks])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "# Initializers\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "# Hidden weights\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_stocks, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "\n",
    "# Output weights\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_4, 1]))\n",
    "bias_out = tf.Variable(bias_initializer([1]))\n",
    "\n",
    "# Hidden layer\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "# Output layer (transpose!)\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))\n",
    "\n",
    "# Cost function\n",
    "mse = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "\n",
    "# Optimizer\n",
    "opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "\n",
    "# Init\n",
    "net.run(tf.global_variables_initializer())\n",
    "\n",
    "# Setup plot\n",
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "line1, = ax1.plot(y_test)\n",
    "line2, = ax1.plot(y_test * 0.5)\n",
    "plt.show()\n",
    "\n",
    "# Fit neural net\n",
    "batch_size = 256\n",
    "mse_train = []\n",
    "mse_test = []\n",
    "\n",
    "# Run\n",
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "\n",
    "    # Shuffle training data\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "    X_train = X_train[shuffle_indices]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "\n",
    "    # Minibatch training\n",
    "    for i in range(0, len(y_train) // batch_size):\n",
    "        start = i * batch_size\n",
    "        batch_x = X_train[start:start + batch_size]\n",
    "        batch_y = y_train[start:start + batch_size]\n",
    "        # Run optimizer with batch\n",
    "        net.run(opt, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "        # Show progress\n",
    "        if np.mod(i, 50) == 0:\n",
    "            # MSE train and test\n",
    "            mse_train.append(net.run(mse, feed_dict={X: X_train, Y: y_train}))\n",
    "            mse_test.append(net.run(mse, feed_dict={X: X_test, Y: y_test}))\n",
    "            print('MSE Train: ', mse_train[-1])\n",
    "            print('MSE Test: ', mse_test[-1])\n",
    "            # Prediction\n",
    "            pred = net.run(out, feed_dict={X: X_test})\n",
    "            line2.set_ydata(pred)\n",
    "            plt.title('Epoch ' + str(e) + ', Batch ' + str(i))\n",
    "            plt.pause(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
